# -*- coding: utf-8 -*-
"""Extraccion_Planillas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zj0y5lYrsmPJ8TUMMXpcAnsoRNiUt8nG

ENLACE DE GOOGLE SHEETS PARA LA GESTION DEL CÓDIGO: https://docs.google.com/spreadsheets/d/1DtoKfMkJn6y_h1D0i_r6Lo6g1xdgxAGN90Z4JeKMG6M/edit?usp=sharing
"""

#Autenticación
from google.colab import auth
auth.authenticate_user()

import gspread
from google.auth import default
import requests
import io
import zipfile

#Credenciales
creds, _ = default()

#Lee la lista de planillas desde Google Sheets
gc = gspread.authorize(creds)
sheet_url = "https://docs.google.com/spreadsheets/d/1DtoKfMkJn6y_h1D0i_r6Lo6g1xdgxAGN90Z4JeKMG6M/edit?gid=0#gid=0"
worksheet = gc.open_by_url(sheet_url).worksheet('Planillas')
planillas = worksheet.col_values(1)[1:]  # columna A sin encabezado

#imprime los numeros de planilla para verificación
print(f"Total de planillas a buscar: {planillas}")

#Busca archivos en unidad compartida
from googleapiclient.discovery import build

SHARED_DRIVE_ID = '0AD6m364rhd3AUk9PVA'  #RECAUDO ARL

service = build('drive', 'v3', credentials=creds)

archivos_encontrados = {}


#Ciclo Para y Mientras para funcionamiento de la extraccion
for planilla in planillas:
    query = f"name contains '{planilla}' and trashed = false"
    page_token = None
    all_files = []
    while True:
        response = service.files().list(
            q=query,
            corpora='drive',
            driveId=SHARED_DRIVE_ID,
            includeItemsFromAllDrives=True,
            supportsAllDrives=True,
            fields='nextPageToken, files(id, name, size, mimeType)',
            pageSize=1000, #Drive API solo permite maximo Mil planillas para extraer
            pageToken=page_token
        ).execute()
        all_files.extend(response.get('files', []))
        page_token = response.get('nextPageToken')
        if not page_token:
            break

    # Filtra solo TXT (por mimeType o extensión .txt)
    txt_files = [
        f for f in all_files
        if (
            (f.get('mimeType') == 'text/plain' or f.get('name','').lower().endswith('.txt'))
            and 'size' in f
        )
    ]

    if not txt_files:
        archivos_encontrados[planilla] = None
        print(f"[{planilla}] No encontrado TXT.")
        continue

    # Selecciona el archivo TXT más pesado
    archivo_pesado = max(txt_files, key=lambda x: int(x['size']))
    archivos_encontrados[planilla] = archivo_pesado
    #imprime el nombre de los archivos encontrados
    print(f"[{planilla}] TXT más pesado: {archivo_pesado['name']}")

#Descarga los archivos y crea un ZIP en memoria
zip_buffer = io.BytesIO()
with zipfile.ZipFile(zip_buffer, 'w') as myzip:
    for planilla, info in archivos_encontrados.items():
        if info is not None:
            file_id = info['id']
            file_name = info['name']
            #imprime el nombre de los archivos que se encuentran en proceso de descarga
            print(f"Descargando: {file_name}")
            downloader = requests.get(
                f"https://www.googleapis.com/drive/v3/files/{file_id}?alt=media",
                headers={"Authorization": f"Bearer {creds.token}"}
            )
            myzip.writestr(file_name, downloader.content)

# Guarda y descarga el ZIP
zip_buffer.seek(0)
                    #Se puede cambiar el nombre de como se guarde el ZIP, sin quitar el ".zip"
with open("/content/planillas_txt_encontradas.zip", "wb") as f:
    f.write(zip_buffer.read())

from google.colab import files as colab_files
                                #Si se cambia el nombre, aqui tambien se tiene que indicar el nombre cambiado, sin quitar el ".zip"
colab_files.download("/content/planillas_txt_encontradas.zip")